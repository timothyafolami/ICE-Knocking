{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and Preprocess Data\n",
    "def load_and_preprocess_data(file_path):\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert Timestamp to datetime and set as index\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "\n",
    "    df.drop(columns=['Knock', 'IgnitionTiming'], inplace=True)\n",
    "    \n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    \n",
    "    return df, scaled_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess data\n",
    "file_path = '../data/engine_knock_data_hourly.csv'  \n",
    "df_resampled, scaled_data, scaler = load_and_preprocess_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RPM</th>\n",
       "      <th>CylinderPressure</th>\n",
       "      <th>BurnRate</th>\n",
       "      <th>Vibration</th>\n",
       "      <th>EGOVoltage</th>\n",
       "      <th>TempSensor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01 00:00:00</th>\n",
       "      <td>3049.671415</td>\n",
       "      <td>30.226362</td>\n",
       "      <td>8.532683</td>\n",
       "      <td>0.493748</td>\n",
       "      <td>0.30</td>\n",
       "      <td>106.963896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 01:00:00</th>\n",
       "      <td>3115.583092</td>\n",
       "      <td>20.206043</td>\n",
       "      <td>7.773047</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>0.45</td>\n",
       "      <td>100.848934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 02:00:00</th>\n",
       "      <td>3314.768854</td>\n",
       "      <td>22.896396</td>\n",
       "      <td>9.217628</td>\n",
       "      <td>0.116642</td>\n",
       "      <td>0.45</td>\n",
       "      <td>110.003050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 03:00:00</th>\n",
       "      <td>3505.856376</td>\n",
       "      <td>12.276180</td>\n",
       "      <td>0.814754</td>\n",
       "      <td>0.077569</td>\n",
       "      <td>0.45</td>\n",
       "      <td>92.596056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 04:00:00</th>\n",
       "      <td>3409.597364</td>\n",
       "      <td>16.095535</td>\n",
       "      <td>6.928412</td>\n",
       "      <td>0.069932</td>\n",
       "      <td>0.45</td>\n",
       "      <td>91.748085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31 19:00:00</th>\n",
       "      <td>2583.022048</td>\n",
       "      <td>18.871620</td>\n",
       "      <td>9.923854</td>\n",
       "      <td>-0.014610</td>\n",
       "      <td>0.45</td>\n",
       "      <td>95.126803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31 20:00:00</th>\n",
       "      <td>2455.293210</td>\n",
       "      <td>21.390331</td>\n",
       "      <td>7.016738</td>\n",
       "      <td>-0.099423</td>\n",
       "      <td>0.45</td>\n",
       "      <td>103.119660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31 21:00:00</th>\n",
       "      <td>2541.669115</td>\n",
       "      <td>22.035972</td>\n",
       "      <td>9.061003</td>\n",
       "      <td>0.077802</td>\n",
       "      <td>0.45</td>\n",
       "      <td>109.012643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31 22:00:00</th>\n",
       "      <td>2818.790208</td>\n",
       "      <td>20.442775</td>\n",
       "      <td>5.506405</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.45</td>\n",
       "      <td>103.814611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31 23:00:00</th>\n",
       "      <td>2835.874329</td>\n",
       "      <td>13.920567</td>\n",
       "      <td>0.833145</td>\n",
       "      <td>0.087226</td>\n",
       "      <td>0.45</td>\n",
       "      <td>94.389918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10944 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             RPM  CylinderPressure  BurnRate  Vibration  \\\n",
       "Timestamp                                                                 \n",
       "2024-01-01 00:00:00  3049.671415         30.226362  8.532683   0.493748   \n",
       "2024-01-01 01:00:00  3115.583092         20.206043  7.773047   0.005990   \n",
       "2024-01-01 02:00:00  3314.768854         22.896396  9.217628   0.116642   \n",
       "2024-01-01 03:00:00  3505.856376         12.276180  0.814754   0.077569   \n",
       "2024-01-01 04:00:00  3409.597364         16.095535  6.928412   0.069932   \n",
       "...                          ...               ...       ...        ...   \n",
       "2025-03-31 19:00:00  2583.022048         18.871620  9.923854  -0.014610   \n",
       "2025-03-31 20:00:00  2455.293210         21.390331  7.016738  -0.099423   \n",
       "2025-03-31 21:00:00  2541.669115         22.035972  9.061003   0.077802   \n",
       "2025-03-31 22:00:00  2818.790208         20.442775  5.506405   0.008902   \n",
       "2025-03-31 23:00:00  2835.874329         13.920567  0.833145   0.087226   \n",
       "\n",
       "                     EGOVoltage  TempSensor  \n",
       "Timestamp                                    \n",
       "2024-01-01 00:00:00        0.30  106.963896  \n",
       "2024-01-01 01:00:00        0.45  100.848934  \n",
       "2024-01-01 02:00:00        0.45  110.003050  \n",
       "2024-01-01 03:00:00        0.45   92.596056  \n",
       "2024-01-01 04:00:00        0.45   91.748085  \n",
       "...                         ...         ...  \n",
       "2025-03-31 19:00:00        0.45   95.126803  \n",
       "2025-03-31 20:00:00        0.45  103.119660  \n",
       "2025-03-31 21:00:00        0.45  109.012643  \n",
       "2025-03-31 22:00:00        0.45  103.814611  \n",
       "2025-03-31 23:00:00        0.45   94.389918  \n",
       "\n",
       "[10944 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.35129955e-01, 8.89685456e-01, 8.48549983e-01, 8.42716887e-01,\n",
       "        8.71714478e-10, 7.51700950e-01],\n",
       "       [5.75842515e-01, 5.75900390e-01, 7.73006403e-01, 2.33264474e-01,\n",
       "        1.00000000e+00, 5.98006873e-01],\n",
       "       [6.98876287e-01, 6.60148466e-01, 9.16665773e-01, 3.71523920e-01,\n",
       "        1.00000000e+00, 8.28087321e-01],\n",
       "       ...,\n",
       "       [2.21345282e-01, 6.33204399e-01, 9.01089837e-01, 3.22994100e-01,\n",
       "        9.99999999e-01, 8.03194358e-01],\n",
       "       [3.92518428e-01, 5.83313640e-01, 5.47595603e-01, 2.36903540e-01,\n",
       "        1.00000000e+00, 6.72546491e-01],\n",
       "       [4.03071009e-01, 3.79071491e-01, 8.28537686e-02, 3.34769279e-01,\n",
       "        9.99999999e-01, 4.35665354e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10944, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.3513e-01, 8.8969e-01, 8.4855e-01, 8.4272e-01, 8.7171e-10, 7.5170e-01],\n",
       "        [5.7584e-01, 5.7590e-01, 7.7301e-01, 2.3326e-01, 1.0000e+00, 5.9801e-01],\n",
       "        [6.9888e-01, 6.6015e-01, 9.1667e-01, 3.7152e-01, 1.0000e+00, 8.2809e-01],\n",
       "        ...,\n",
       "        [2.2135e-01, 6.3320e-01, 9.0109e-01, 3.2299e-01, 1.0000e+00, 8.0319e-01],\n",
       "        [3.9252e-01, 5.8331e-01, 5.4760e-01, 2.3690e-01, 1.0000e+00, 6.7255e-01],\n",
       "        [4.0307e-01, 3.7907e-01, 8.2854e-02, 3.3477e-01, 1.0000e+00, 4.3567e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to tensor\n",
    "data_tensor = torch.tensor(scaled_data, dtype=torch.float32)\n",
    "data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create Sequences for Training\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_length):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx + self.seq_length]\n",
    "        y = self.data[idx + self.seq_length]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create dataset and dataloader\n",
    "seq_length = 72  # Number of timesteps to look back (3 days look back)\n",
    "dataset = TimeSeriesDataset(data_tensor, seq_length)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define model, loss, and optimizer\n",
    "input_size = df_resampled.shape[1]  # Number of features\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "output_size = df_resampled.shape[1]\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(6, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM + Attention\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, hidden_size]\n",
    "        attn_weights = torch.softmax(self.attn(x), dim=1)  # [batch_size, seq_len, 1]\n",
    "        context = torch.sum(attn_weights * x, dim=1)  # [batch_size, hidden_size]\n",
    "        return context\n",
    "\n",
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMWithAttention, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.attention(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "## Params\n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "\n",
    "lstm_attn_model = LSTMWithAttention(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "lstm_attn_optimizer = torch.optim.Adam(lstm_attn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_attn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, d_model, nhead, num_encoder_layers, output_size):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Linear(input_size, d_model)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead),\n",
    "            num_layers=num_encoder_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, input_size]\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, d_model]\n",
    "        x = self.transformer(x)  # [batch_size, seq_len, d_model]\n",
    "        x = self.fc(x[:, -1, :])  # Take last token's output\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Define model\n",
    "input_size = df_resampled.shape[1]  # Number of features\n",
    "d_model = 64\n",
    "nhead = 8\n",
    "num_encoder_layers = 3\n",
    "output_size = df_resampled.shape[1]\n",
    "\n",
    "trans_model = TransformerModel(input_size, d_model, nhead, num_encoder_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "trans_optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train the Model\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_y_true = []\n",
    "        all_y_pred = []\n",
    "        \n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for X_batch, y_batch in pbar:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Collect true and predicted values\n",
    "            y_true = y_batch.cpu().numpy()\n",
    "            y_pred = outputs.detach().cpu().numpy()\n",
    "            \n",
    "            all_y_true.extend(y_true)\n",
    "            all_y_pred.extend(y_pred)\n",
    "        \n",
    "        # After processing all batches in the epoch\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        r2 = r2_score(all_y_true, all_y_pred, multioutput='variance_weighted')\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}, RÂ²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Forecast Future Values\n",
    "def forecast(model, last_sequence, n_steps, scaler):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_steps):\n",
    "            pred = model(last_sequence)\n",
    "            predictions.append(pred.numpy()[0])\n",
    "            # Update the sequence by appending the prediction and removing the first element\n",
    "            last_sequence = torch.cat([last_sequence[:, 1:], pred.unsqueeze(0)], dim=1)\n",
    "    \n",
    "    # Inverse transform the predictions\n",
    "    forecasted_values = scaler.inverse_transform(np.array(predictions))\n",
    "    return forecasted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, scaler):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            \n",
    "            # Append actual and predicted values\n",
    "            actuals.append(y_batch.cpu().numpy())\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all predictions and actuals\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    \n",
    "    # Inverse transform the predictions and actuals\n",
    "    actuals_inv = scaler.inverse_transform(actuals)\n",
    "    predictions_inv = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    # Calculate RÂ² Score\n",
    "    r2 = r2_score(actuals_inv, predictions_inv, multioutput='variance_weighted')\n",
    "    print(f\"RÂ² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train the model\n",
    "num_epochs = 25\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, dataloader, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Forecast future values\n",
    "last_seq = data_tensor[-seq_length:]\n",
    "last_seq = last_seq.unsqueeze(0)  # Add batch dimension\n",
    "n_steps = 720  # Forecast next 720 steps (30 dayss)\n",
    "\n",
    "forecasted_values = forecast(model, last_seq, n_steps, scaler)\n",
    "\n",
    "# Create a DataFrame for forecasted values\n",
    "forecast_df = pd.DataFrame(\n",
    "    forecasted_values,\n",
    "    columns=df_resampled.columns,\n",
    "    index=pd.date_range(\n",
    "        start=df_resampled.index[-1] + pd.Timedelta(hours=1),\n",
    "        periods=n_steps,\n",
    "        freq='H'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for each feature\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "fig.suptitle('Forecasted Values for Next 30 Days')\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each feature\n",
    "for idx, column in enumerate(forecast_df.columns):\n",
    "    axes[idx].plot(forecast_df.index, forecast_df[column])\n",
    "    axes[idx].set_title(column)\n",
    "    axes[idx].set_xlabel('Date')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].grid(True)\n",
    "    # Rotate x-axis labels for better readability\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for each feature\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "fig.suptitle('Historical vs Forecasted Values')\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Get last 30 days of historical data\n",
    "last_30_days = df_resampled.last('30D')\n",
    "\n",
    "# Plot each feature\n",
    "for idx, column in enumerate(forecast_df.columns):\n",
    "    # Plot historical data\n",
    "    axes[idx].plot(last_30_days.index, last_30_days[column], label='Historical', color='blue')\n",
    "    # Plot forecasted data\n",
    "    axes[idx].plot(forecast_df.index, forecast_df[column], label='Forecast', color='red')\n",
    "    axes[idx].set_title(column)\n",
    "    axes[idx].set_xlabel('Date')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].grid(True)\n",
    "    axes[idx].legend()\n",
    "    # Rotate x-axis labels for better readability\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print or save the forecasted DataFrame\n",
    "forecast_df.to_csv('forecasted_data_1.csv', index_label='Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(lstm_attn_model, dataloader, criterion, lstm_attn_optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(lstm_attn_model, dataloader, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Forecast future values\n",
    "last_seq = data_tensor[-seq_length:]\n",
    "last_seq = last_seq.unsqueeze(0)  # Add batch dimension\n",
    "n_steps = 720  # Forecast next 720 steps (30 dayss)\n",
    "\n",
    "forecasted_values = forecast(lstm_attn_model, last_seq, n_steps, scaler)\n",
    "\n",
    "# Create a DataFrame for forecasted values\n",
    "forecast_df = pd.DataFrame(\n",
    "    forecasted_values,\n",
    "    columns=df_resampled.columns,\n",
    "    index=pd.date_range(\n",
    "        start=df_resampled.index[-1] + pd.Timedelta(hours=1),\n",
    "        periods=n_steps,\n",
    "        freq='H'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for each feature\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "fig.suptitle('Forecasted Values for Next 30 Days')\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each feature\n",
    "for idx, column in enumerate(forecast_df.columns):\n",
    "    axes[idx].plot(forecast_df.index, forecast_df[column])\n",
    "    axes[idx].set_title(column)\n",
    "    axes[idx].set_xlabel('Date')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].grid(True)\n",
    "    # Rotate x-axis labels for better readability\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for each feature\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "fig.suptitle('Historical vs Forecasted Values')\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Get last 30 days of historical data\n",
    "last_30_days = df_resampled.last('30D')\n",
    "\n",
    "# Plot each feature\n",
    "for idx, column in enumerate(forecast_df.columns):\n",
    "    # Plot historical data\n",
    "    axes[idx].plot(last_30_days.index, last_30_days[column], label='Historical', color='blue')\n",
    "    # Plot forecasted data\n",
    "    axes[idx].plot(forecast_df.index, forecast_df[column], label='Forecast', color='red')\n",
    "    axes[idx].set_title(column)\n",
    "    axes[idx].set_xlabel('Date')\n",
    "    axes[idx].set_ylabel('Value')\n",
    "    axes[idx].grid(True)\n",
    "    axes[idx].legend()\n",
    "    # Rotate x-axis labels for better readability\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print or save the forecasted DataFrame\n",
    "# print(forecast_df.head())\n",
    "# forecast_df.to_csv('forecasted_data.csv', index_label='Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(trans_model, dataloader, criterion, trans_optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(trans_model, dataloader, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Forecast future values\n",
    "# last_seq = data_tensor[-seq_length:]\n",
    "# last_seq = last_seq.unsqueeze(0)  # Add batch dimension\n",
    "# n_steps = 720  # Forecast next 720 steps (1 hour at 1-minute intervals)\n",
    "\n",
    "# forecasted_values = forecast(model, last_seq, n_steps, scaler)\n",
    "\n",
    "# # Create a DataFrame for forecasted values\n",
    "# forecast_df = pd.DataFrame(\n",
    "#     forecasted_values,\n",
    "#     columns=df_resampled.columns,\n",
    "#     index=pd.date_range(\n",
    "#         start=df_resampled.index[-1] + pd.Timedelta(hours=1),\n",
    "#         periods=n_steps,\n",
    "#         freq='T'\n",
    "#     )\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print or save the forecasted DataFrame\n",
    "# print(forecast_df.head())\n",
    "# forecast_df.to_csv('forecasted_data.csv', index_label='Timestamp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "betzflip-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
